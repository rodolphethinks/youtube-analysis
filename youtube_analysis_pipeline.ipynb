{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e869c0e4",
   "metadata": {},
   "source": [
    "## Setup & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd07454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (run once)\n",
    "# !pip install google-api-python-client google-generativeai pandas yt-dlp transformers torch python-docx openpyxl tqdm matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9a8322",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add src directory to path\n",
    "sys.path.insert(0, os.path.join(os.getcwd(), 'src'))\n",
    "\n",
    "# Load environment variables\n",
    "API_KEY = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "if not API_KEY:\n",
    "    raise ValueError(\"Please set the GOOGLE_API_KEY environment variable\")\n",
    "\n",
    "print(\"‚úì API Key loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3752089e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import PipelineConfig, CarModel, SCENIC_CONFIG, KOLEOS_CONFIG, TORRES_CONFIG\n",
    "from pipeline import YouTubeAnalysisPipeline\n",
    "\n",
    "# Initialize configuration\n",
    "config = PipelineConfig(\n",
    "    google_api_key=API_KEY,\n",
    "    max_search_results=50,\n",
    "    published_after=\"2024-04-01T00:00:00Z\",\n",
    "    max_comments_per_video=100,\n",
    "    output_dir=\"output\",\n",
    ")\n",
    "\n",
    "# Initialize pipeline\n",
    "pipeline = YouTubeAnalysisPipeline(config)\n",
    "\n",
    "print(\"‚úì Pipeline initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4831d3f6",
   "metadata": {},
   "source": [
    "## Select Car Model to Analyze\n",
    "\n",
    "Choose from predefined models or create a custom configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140a96e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Use predefined configuration\n",
    "car_model = SCENIC_CONFIG  # Renault Scenic E-Tech\n",
    "\n",
    "# Option 2: Create custom configuration\n",
    "# car_model = CarModel(\n",
    "#     company=\"Î•¥ÎÖ∏\",\n",
    "#     model=\"Scenic E-Tech\",\n",
    "#     search_queries=[\n",
    "#         \"Î•¥ÎÖ∏ ÏÑ∏Îãâ E-Tech\",\n",
    "#         \"ÏÑ∏Îãâ Ï†ÑÍ∏∞Ï∞® ÏãúÏäπÍ∏∞\",\n",
    "#         \"Î•¥ÎÖ∏ ÏÑ∏Îãâ Ï†ÑÍ∏∞Ï∞® Î¶¨Î∑∞\",\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "print(f\"Selected: {car_model.company} {car_model.model}\")\n",
    "print(f\"Search queries: {car_model.search_queries}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f630bf",
   "metadata": {},
   "source": [
    "---\n",
    "## Stage 1-2: Video Discovery & Comment Collection\n",
    "\n",
    "Search YouTube for relevant videos and collect comments.\n",
    "\n",
    "**Expected time:** ~30 seconds for 50 videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a88a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Discover videos and collect comments\n",
    "videos_df, comments_df = pipeline.run_discovery(car_model)\n",
    "\n",
    "print(f\"\\nüìä Results:\")\n",
    "print(f\"   Videos found: {len(videos_df)}\")\n",
    "print(f\"   Comments collected: {len(comments_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db40c239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview discovered videos (top 10 by views)\n",
    "videos_df[['Title', 'Channel Title', 'Views', 'Likes', 'Duration']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21e870e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Filter videos by title pattern\n",
    "# Uncomment and modify the regex pattern as needed\n",
    "\n",
    "# filtered_videos = videos_df[videos_df['Title'].str.contains(r\"(?=.*Î•¥ÎÖ∏)(?=.*ÏÑ∏Îãâ)\", na=False, regex=True)]\n",
    "# print(f\"Filtered to {len(filtered_videos)} videos\")\n",
    "# filtered_videos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5735c902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview comments\n",
    "comments_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e61dbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save comments to CSV for backup\n",
    "comments_df.to_csv(f\"{car_model.identifier}_comments.csv\", index=False)\n",
    "print(f\"‚úì Comments saved to {car_model.identifier}_comments.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8951eef0",
   "metadata": {},
   "source": [
    "---\n",
    "## Stage 3: Video Transcription (Optional)\n",
    "\n",
    "Download audio and transcribe using Whisper.\n",
    "\n",
    "**Expected time:** ~3-4 minutes per video (10 videos ‚âà 30-40 minutes)\n",
    "\n",
    "‚ö†Ô∏è **Note:** This stage requires significant compute resources and time. You can skip it if you only want to analyze comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ebaeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for transcription\n",
    "MAX_VIDEOS_TO_TRANSCRIBE = 10  # Limit to reduce processing time\n",
    "SKIP_TRANSCRIPTION = True  # Set to False to enable transcription\n",
    "\n",
    "if not SKIP_TRANSCRIPTION:\n",
    "    print(f\"Will transcribe up to {MAX_VIDEOS_TO_TRANSCRIBE} videos\")\n",
    "else:\n",
    "    print(\"Transcription skipped - analysis will be based on comments only\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f9f7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "if not SKIP_TRANSCRIPTION:\n",
    "    transcriptions = pipeline.run_transcription(\n",
    "        car_model,\n",
    "        max_videos=MAX_VIDEOS_TO_TRANSCRIBE,\n",
    "        whisper_model=\"large-v3\"  # Options: tiny, base, small, medium, large-v3\n",
    "    )\n",
    "    print(f\"\\n‚úì Successfully transcribed {len(transcriptions)} videos\")\n",
    "else:\n",
    "    transcriptions = {}\n",
    "    print(\"Transcription skipped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a781fe5e",
   "metadata": {},
   "source": [
    "---\n",
    "## Stage 4: AI-Powered Analysis\n",
    "\n",
    "Analyze transcripts and comments using Google Gemini for:\n",
    "- Sentiment analysis\n",
    "- Key strengths & weaknesses\n",
    "- Competitor mentions\n",
    "- User persona generation\n",
    "\n",
    "**Expected time:** ~1-2 seconds per video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c004036",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Run analysis\n",
    "video_analyses, comment_analyses = pipeline.run_analysis(car_model)\n",
    "\n",
    "print(f\"\\nüìä Analysis Results:\")\n",
    "print(f\"   Video analyses: {len(video_analyses)}\")\n",
    "print(f\"   Comment analyses: {len(comment_analyses)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b01581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview analysis results\n",
    "from analysis import analysis_to_dataframe\n",
    "\n",
    "if video_analyses:\n",
    "    analysis_df = analysis_to_dataframe(video_analyses)\n",
    "    display(analysis_df[['Video URL', 'Overall Sentiment', 'Sentiment Score', 'Key Strengths', 'Key Weaknesses']].head())\n",
    "else:\n",
    "    print(\"No video analyses available (transcription was skipped)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7498e5f0",
   "metadata": {},
   "source": [
    "---\n",
    "## Stage 5: Report Generation\n",
    "\n",
    "Generate comprehensive reports in multiple formats:\n",
    "- Word document with executive summary\n",
    "- Excel file with detailed data\n",
    "- CSV export of comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0950e722",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Generate reports\n",
    "output_files = pipeline.run_reporting(\n",
    "    car_model,\n",
    "    generate_word=True,\n",
    "    generate_excel=True\n",
    ")\n",
    "\n",
    "print(\"\\nüìÅ Generated Files:\")\n",
    "for name, path in output_files.items():\n",
    "    print(f\"   {name}: {path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d6dbb1",
   "metadata": {},
   "source": [
    "---\n",
    "## Alternative: Run Full Pipeline in One Command\n",
    "\n",
    "Use this for automated end-to-end processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5feb290e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run full pipeline (uncomment to use)\n",
    "# output_files = pipeline.run_full_pipeline(\n",
    "#     car_model,\n",
    "#     max_videos_to_transcribe=10,\n",
    "#     skip_transcription=True  # Set to False to include transcription\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3206a3bf",
   "metadata": {},
   "source": [
    "---\n",
    "## Multi-Model Comparison (Optional)\n",
    "\n",
    "Compare sentiment analysis across multiple car models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c157c150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Analyze multiple car models\n",
    "# from config import KOLEOS_CONFIG, SORENTO_CONFIG, SANTAFE_CONFIG\n",
    "# \n",
    "# models_to_compare = [SCENIC_CONFIG, KOLEOS_CONFIG, SORENTO_CONFIG]\n",
    "# \n",
    "# all_results = {}\n",
    "# for model in models_to_compare:\n",
    "#     pipeline.run_full_pipeline(model, skip_transcription=True)\n",
    "#     all_results[model.identifier] = pipeline.results[model.identifier]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ead5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generate comparison visualization\n",
    "# from reports import MultiModelReportGenerator\n",
    "# \n",
    "# multi_report = MultiModelReportGenerator(pipeline.gemini_client, config.output_dir)\n",
    "# \n",
    "# # Create comparison DataFrame\n",
    "# model_analyses = {}\n",
    "# for model_id, results in all_results.items():\n",
    "#     if 'video_analyses' in results:\n",
    "#         model_analyses[model_id] = analysis_to_dataframe(results['video_analyses'])\n",
    "# \n",
    "# # Generate sentiment comparison\n",
    "# sentiment_comparison = multi_report.generate_sentiment_comparison(model_analyses)\n",
    "# display(sentiment_comparison)\n",
    "# \n",
    "# # Create visualization\n",
    "# multi_report.visualize_sentiment(sentiment_comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2554d1d2",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "Pipeline execution complete! Check the `output/` directory for generated reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3780cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List generated files\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "output_dir = Path(\"output\")\n",
    "if output_dir.exists():\n",
    "    print(\"üìÅ Output files:\")\n",
    "    for f in sorted(output_dir.iterdir()):\n",
    "        size = f.stat().st_size / 1024  # KB\n",
    "        print(f\"   {f.name} ({size:.1f} KB)\")\n",
    "else:\n",
    "    print(\"No output files generated yet.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
